{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Blog Authorship Solution.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xqPj0YR4IbKL",
        "v4Qz2d8yO3Wc",
        "gJCSbPVLSM4Y",
        "nx77mhDaamWL",
        "ihCdZZAUa3oz",
        "3ceQ9HfVbArk",
        "sK7qIYMySfad",
        "_PO8PPvXdGzE",
        "Tw0DwkHAgw3O",
        "f-UYAv1MYPXa",
        "zsIINhurYd3S",
        "foyKVYPpkP1c",
        "nL426EOBCGYQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqPj0YR4IbKL"
      },
      "source": [
        "###Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOozdLwkNw7-"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"/content/drive/MyDrive/AIML Projects/Statistical NLP project/blogtext.csv\")"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "_HSOosmmOUNw",
        "outputId": "1af632aa-5c4b-466b-fa28-0fe0b849a8b5"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>14,May,2004</td>\n",
              "      <td>Info has been found (+/- 100 pages,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>13,May,2004</td>\n",
              "      <td>These are the team members:   Drewe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>12,May,2004</td>\n",
              "      <td>In het kader van kernfusie op aarde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>12,May,2004</td>\n",
              "      <td>testing!!!  testing!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3581210</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>11,June,2004</td>\n",
              "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                               text\n",
              "0  2059027  ...             Info has been found (+/- 100 pages,...\n",
              "1  2059027  ...             These are the team members:   Drewe...\n",
              "2  2059027  ...             In het kader van kernfusie op aarde...\n",
              "3  2059027  ...                   testing!!!  testing!!!          \n",
              "4  3581210  ...               Thanks to Yahoo!'s Toolbar I can ...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDQmxE0flFDl"
      },
      "source": [
        "###Preprocesing Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4Qz2d8yO3Wc"
      },
      "source": [
        "#####We've included the data, next steps would include preprocessing it based on,\n",
        "1. Ensure no Null/Nan values are present \n",
        "2. Keep only text items\n",
        "3. Normalize the input \n",
        "    a. remove stop words\n",
        "    b. Lemmatize the words\n",
        "    c. Stem the words\n",
        "4. Tokenize the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vJHheY-QNe4"
      },
      "source": [
        "df_t = df[['text']].head(4000)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7kxRdrUQQbGF",
        "outputId": "ce7d62e0-4593-4587-e55e-f29905d9a0ef"
      },
      "source": [
        "df_t.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Info has been found (+/- 100 pages,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>These are the team members:   Drewe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In het kader van kernfusie op aarde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>testing!!!  testing!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0             Info has been found (+/- 100 pages,...\n",
              "1             These are the team members:   Drewe...\n",
              "2             In het kader van kernfusie op aarde...\n",
              "3                   testing!!!  testing!!!          \n",
              "4               Thanks to Yahoo!'s Toolbar I can ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvd7jO9xRAR7",
        "outputId": "d71eea37-7271-4fbb-c167-3b8b7a54d8e3"
      },
      "source": [
        "df_t.isnull().sum()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_nGzwTwSCEF",
        "outputId": "bcc8f2ed-d481-4b98-dfb0-2211206de13b"
      },
      "source": [
        "df_t.isna().sum()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJCSbPVLSM4Y"
      },
      "source": [
        "####Remove unwanted characters and convert this to lower case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg1gJKrdaEik"
      },
      "source": [
        "#import regular expression\n",
        "import re"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVjoo0FGSLFA"
      },
      "source": [
        "df_t.text= df_t.text.apply(lambda x: re.sub('[^A-Za-z]+', ' ', x))"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx77mhDaamWL"
      },
      "source": [
        "####Remove unwanted spaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCo8_qEkax9f"
      },
      "source": [
        "df_t.text = df_t.text.apply(lambda x: x.strip())"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihCdZZAUa3oz"
      },
      "source": [
        "####Convert to lower case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr1Yw9L_Z5Z1"
      },
      "source": [
        "df_t.text = df_t.text.apply(lambda x: x.lower())"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ceQ9HfVbArk"
      },
      "source": [
        "####Remove Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PEIkqt0Pa2gZ",
        "outputId": "7c5dc30d-60a3-4c80-91f4-10c1ee00b72a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')#download stopwords dictionary from NLTK"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaIA3_RJbhme"
      },
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTl4O_-AbNhc"
      },
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oYF-H1XbUd8"
      },
      "source": [
        "df_t.text = df_t.text.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Q6ngY4DPbuNz",
        "outputId": "08c4080d-f1f4-457b-ebc6-a01d817834ba"
      },
      "source": [
        "#random check of any row\n",
        "df_t['text'].iloc[3212]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'yay dubya coming visit england huge amounts people coming give great leader urllink warm welcome wait til gets urllink'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI5f1IW00XbO"
      },
      "source": [
        "###Merging and creating multi label Y values "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqWY-Af44IAg",
        "outputId": "a81f1fb1-a9ec-44f9-ae48-c78ee0595be0"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'gender', 'age', 'topic', 'sign', 'date', 'text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "9al0wDK-3_wI",
        "outputId": "40a44baf-279c-427b-b1bf-1779baa52416"
      },
      "source": [
        "df['age']=df['age'].astype(str)\n",
        "#df_t['labels'] = df[['gender','age','topic','sign']].apply(lambda x: ','.join(x), axis = 1)\n",
        "df_t['labels'] = df.apply(lambda row: [row['gender'].lower(), str(row['age']), row['topic'].lower(), row['sign'].lower()], axis=1)\n",
        "df_t.head()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "      <th>labels2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>info found pages mb pdf files wait untill team...</td>\n",
              "      <td>[male, 15, student, leo]</td>\n",
              "      <td>male , 15 , Student , Leo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>team members drewes van der laag urllink mail ...</td>\n",
              "      <td>[male, 15, student, leo]</td>\n",
              "      <td>male , 15 , Student , Leo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
              "      <td>[male, 15, student, leo]</td>\n",
              "      <td>male , 15 , Student , Leo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>testing testing</td>\n",
              "      <td>[male, 15, student, leo]</td>\n",
              "      <td>male , 15 , Student , Leo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
              "      <td>[male, 33, investmentbanking, aquarius]</td>\n",
              "      <td>male , 33 , InvestmentBanking , Aquarius</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                   labels2\n",
              "0  info found pages mb pdf files wait untill team...  ...                 male , 15 , Student , Leo\n",
              "1  team members drewes van der laag urllink mail ...  ...                 male , 15 , Student , Leo\n",
              "2  het kader van kernfusie op aarde maak je eigen...  ...                 male , 15 , Student , Leo\n",
              "3                                    testing testing  ...                 male , 15 , Student , Leo\n",
              "4  thanks yahoo toolbar capture urls popups means...  ...  male , 33 , InvestmentBanking , Aquarius\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sK7qIYMySfad"
      },
      "source": [
        "###Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "tpKFc_djSXmM",
        "outputId": "d2d11fe0-c0d3-45d4-c9dd-ac9e8cbdea16"
      },
      "source": [
        "#Stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "  \n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "words = word_tokenize(df_t.text)\n",
        "  \n",
        "for w in words:\n",
        "    print(w, \" : \", ps.stem(w))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-38ccf44bf99a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstemmer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserver_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     return [token for sent in sentences\n\u001b[1;32m    130\u001b[0m             for token in _treebank_word_tokenizer.tokenize(sent)]\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tokenizers/punkt/{0}.pickle'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'raw'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nltk'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'file'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "y9Fyw4TdRE78",
        "outputId": "5a4b6f82-c16f-4aaf-80ce-5c45c441330f"
      },
      "source": [
        "#Lemmatization\n",
        "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    lemm = [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
        "    return(\" \".join(lemm)) \n",
        "\n",
        "df_t[\"text\"] = df_t.text.apply(lemmatize_text)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-fb3e647e7a14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmatize_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-fb3e647e7a14>\u001b[0m in \u001b[0;36mlemmatize_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlemmatize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlemm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-fb3e647e7a14>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlemmatize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mlemm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/stem/wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PO8PPvXdGzE"
      },
      "source": [
        "###Train_Test_Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck4XhUj8c2ai"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, x_test, y_train, y_test = train_test_split(df_t.text.values,df_t.labels.values, test_size=0.25, random_state=56 )"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odNepy77dq9r",
        "outputId": "37c5263d-1202-4baf-cf21-0522789f221c"
      },
      "source": [
        "print(X_train.shape)\n",
        "x_test.shape"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq0nsNK8IGQv",
        "outputId": "b0890ec5-fd25-4786-a587-0dbdee62e2ea"
      },
      "source": [
        "y_train[2991]"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['male', '15', 'student', 'aquarius']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw0DwkHAgw3O"
      },
      "source": [
        "###Vectorize features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-UYAv1MYPXa"
      },
      "source": [
        "####Tf_IDF Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xACDP19tduxe"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tf_idf = TfidfVectorizer(ngram_range=(1,2),max_features=20000)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuAV29Cxh3aK"
      },
      "source": [
        "input_data=df_t.text.values\n",
        "input_vectors=tf_idf.fit(input_data)\n",
        "X_trainv=tf_idf.transform(X_train)\n",
        "x_testv=tf_idf.transform(x_test)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jeq0Qetdial5",
        "outputId": "9cf4b7cb-a0e1-4086-8143-147998a33554"
      },
      "source": [
        "print(X_trainv[2245])#,X_trainv.shape)\n",
        "print(x_testv[984])#,x_testv.shape)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 18510)\t0.39370048317955497\n",
            "  (0, 10676)\t0.45380258680428087\n",
            "  (0, 9249)\t0.4250021733051824\n",
            "  (0, 8669)\t0.4094321711369768\n",
            "  (0, 7351)\t0.31274563215882123\n",
            "  (0, 4208)\t0.43930827586495597\n",
            "  (0, 19719)\t0.12878808137950393\n",
            "  (0, 19646)\t0.04876470571257804\n",
            "  (0, 18397)\t0.21549724334747386\n",
            "  (0, 17784)\t0.06995608460834722\n",
            "  (0, 17689)\t0.046164974057414584\n",
            "  (0, 17331)\t0.13717783279087756\n",
            "  (0, 17329)\t0.056346073516481354\n",
            "  (0, 16950)\t0.11756716720049198\n",
            "  (0, 16947)\t0.05754185958724\n",
            "  (0, 16812)\t0.10404217656287547\n",
            "  (0, 16217)\t0.12878808137950393\n",
            "  (0, 15447)\t0.09058705058227486\n",
            "  (0, 15312)\t0.16400299521069317\n",
            "  (0, 15280)\t0.0833493374002035\n",
            "  (0, 15259)\t0.07132986975236581\n",
            "  (0, 13949)\t0.14116103378781816\n",
            "  (0, 13948)\t0.1084487269773085\n",
            "  (0, 13698)\t0.06713373902887564\n",
            "  (0, 13141)\t0.13392332060574683\n",
            "  (0, 12860)\t0.13392332060574683\n",
            "  (0, 12433)\t0.08702887911926452\n",
            "  (0, 12272)\t0.09223595102626964\n",
            "  (0, 11749)\t0.09572228980851774\n",
            "  (0, 10953)\t0.08200149760534658\n",
            "  (0, 10630)\t0.12480488038256334\n",
            "  :\t:\n",
            "  (0, 5260)\t0.1115610041701956\n",
            "  (0, 5204)\t0.09537566926542271\n",
            "  (0, 4844)\t0.10774862167373693\n",
            "  (0, 4824)\t0.14116103378781816\n",
            "  (0, 4600)\t0.19215154913798854\n",
            "  (0, 3790)\t0.08639507063129044\n",
            "  (0, 3615)\t0.12310355582722989\n",
            "  (0, 3605)\t0.07622867642169785\n",
            "  (0, 3572)\t0.11756716720049198\n",
            "  (0, 3497)\t0.21549724334747386\n",
            "  (0, 3495)\t0.09718027509488641\n",
            "  (0, 3122)\t0.12878808137950393\n",
            "  (0, 2840)\t0.13392332060574683\n",
            "  (0, 2832)\t0.06068950745962756\n",
            "  (0, 2374)\t0.13117166976058117\n",
            "  (0, 1306)\t0.0903264562157068\n",
            "  (0, 1274)\t0.10244256394701212\n",
            "  (0, 1058)\t0.051249429758421755\n",
            "  (0, 1017)\t0.0673466687554252\n",
            "  (0, 945)\t0.09961820262623858\n",
            "  (0, 776)\t0.11073060341891565\n",
            "  (0, 678)\t0.07262528543588406\n",
            "  (0, 531)\t0.12310355582722989\n",
            "  (0, 402)\t0.05745959954728354\n",
            "  (0, 248)\t0.07622867642169785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsIINhurYd3S"
      },
      "source": [
        "####Count Vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbvDKgCjYhaK"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer(ngram_range=(1,2),max_features=20000)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AlDclNGZV1D"
      },
      "source": [
        "input_cvectors=cv.fit(input_data)\n",
        "X_traincv=cv.transform(X_train)\n",
        "x_testcv=cv.transform(x_test)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xhSzF6ZaXW-",
        "outputId": "38824b8f-a9b5-428c-d7d8-dbf330b1889c"
      },
      "source": [
        "print(X_traincv.shape)\n",
        "print(x_testcv.shape)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000, 20000)\n",
            "(1000, 20000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foyKVYPpkP1c"
      },
      "source": [
        "####Document term matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJra_sJqifM-",
        "outputId": "95f88efd-016f-4169-f1a4-6bdd96be82c6"
      },
      "source": [
        "df_dtmtrain = pd.DataFrame(X_traincv.toarray(), columns=cv.get_feature_names())\n",
        "print(df_dtmtrain.head())"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   aa  aal  aaron  aba  abandon  ...  zodiac  zombie  zone  zoo  zoom\n",
            "0   0    0      0    0        0  ...       0       0     0    0     0\n",
            "1   0    0      0    0        0  ...       0       0     0    0     0\n",
            "2   0    0      0    0        0  ...       0       0     0    0     0\n",
            "3   0    0      0    0        0  ...       0       0     0    0     0\n",
            "4   0    0      0    0        0  ...       0       0     0    0     0\n",
            "\n",
            "[5 rows x 20000 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFQbojEkkdon",
        "outputId": "f6778783-3f96-41d7-ebfe-42b4fd2703a3"
      },
      "source": [
        "df_dtmtest = pd.DataFrame(x_testcv.toarray(), columns=cv.get_feature_names())\n",
        "print(df_dtmtest.head())\n",
        "print(df_dtmtest.shape)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   aa  aal  aaron  aba  abandon  ...  zodiac  zombie  zone  zoo  zoom\n",
            "0   0    0      0    0        0  ...       0       0     0    0     0\n",
            "1   0    0      0    0        0  ...       0       0     0    0     0\n",
            "2   0    0      0    0        0  ...       0       0     0    0     0\n",
            "3   0    0      0    0        0  ...       0       0     0    0     0\n",
            "4   0    0      0    0        0  ...       0       0     0    0     0\n",
            "\n",
            "[5 rows x 20000 columns]\n",
            "(1000, 20000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j38mjbIh48O7"
      },
      "source": [
        "###Transform Labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPTUJFAcP5Zn"
      },
      "source": [
        "####Dictionary to get the count of every label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qjyt-lwc3UD",
        "outputId": "7ecc6a1f-7d15-4ee7-f687-ee4a6f8325e8"
      },
      "source": [
        "import numpy as np\n",
        "cv2=CountVectorizer(ngram_range=(1,1),min_df=1)\n",
        "df_t['labels2']=np.nan\n",
        "for i in range(len(df_t.labels)):\n",
        "  df_t['labels2'].iloc[i]=' , '.join([str(item) for item in df_t.labels.iloc[i]])"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "t3_JYtOrOgRp",
        "outputId": "e554024e-dfee-4fc1-cede-7817ec342ebc"
      },
      "source": [
        "df_t.head(5)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "      <th>labels2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>info found pages mb pdf files wait untill team...</td>\n",
              "      <td>[male, 15, student, leo]</td>\n",
              "      <td>male , 15 , student , leo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>team members drewes van der laag urllink mail ...</td>\n",
              "      <td>[male, 15, student, leo]</td>\n",
              "      <td>male , 15 , student , leo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>het kader van kernfusie op aarde maak je eigen...</td>\n",
              "      <td>[male, 15, student, leo]</td>\n",
              "      <td>male , 15 , student , leo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>testing testing</td>\n",
              "      <td>[male, 15, student, leo]</td>\n",
              "      <td>male , 15 , student , leo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>thanks yahoo toolbar capture urls popups means...</td>\n",
              "      <td>[male, 33, investmentbanking, aquarius]</td>\n",
              "      <td>male , 33 , investmentbanking , aquarius</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                   labels2\n",
              "0  info found pages mb pdf files wait untill team...  ...                 male , 15 , student , leo\n",
              "1  team members drewes van der laag urllink mail ...  ...                 male , 15 , student , leo\n",
              "2  het kader van kernfusie op aarde maak je eigen...  ...                 male , 15 , student , leo\n",
              "3                                    testing testing  ...                 male , 15 , student , leo\n",
              "4  thanks yahoo toolbar capture urls popups means...  ...  male , 33 , investmentbanking , aquarius\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh2beMiVOkqB"
      },
      "source": [
        "labels_cv=cv2.fit(df_t.labels2.values)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFi-t0IVe6dg",
        "outputId": "7d2b795c-db7e-4634-d3d4-b9cd6f15d1bc"
      },
      "source": [
        "dictionary={}\n",
        "dictionary=cv2.vocabulary_\n",
        "dictionary"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'14': 0,\n",
              " '15': 1,\n",
              " '16': 2,\n",
              " '17': 3,\n",
              " '23': 4,\n",
              " '24': 5,\n",
              " '25': 6,\n",
              " '26': 7,\n",
              " '27': 8,\n",
              " '33': 9,\n",
              " '34': 10,\n",
              " '35': 11,\n",
              " '36': 12,\n",
              " '37': 13,\n",
              " '39': 14,\n",
              " '41': 15,\n",
              " '44': 16,\n",
              " '45': 17,\n",
              " 'accounting': 18,\n",
              " 'aquarius': 19,\n",
              " 'aries': 20,\n",
              " 'arts': 21,\n",
              " 'banking': 22,\n",
              " 'businessservices': 23,\n",
              " 'cancer': 24,\n",
              " 'capricorn': 25,\n",
              " 'communications': 26,\n",
              " 'education': 27,\n",
              " 'engineering': 28,\n",
              " 'female': 29,\n",
              " 'gemini': 30,\n",
              " 'indunk': 31,\n",
              " 'internet': 32,\n",
              " 'investmentbanking': 33,\n",
              " 'leo': 34,\n",
              " 'libra': 35,\n",
              " 'libraries': 36,\n",
              " 'male': 37,\n",
              " 'media': 38,\n",
              " 'museums': 39,\n",
              " 'non': 40,\n",
              " 'pisces': 41,\n",
              " 'profit': 42,\n",
              " 'recreation': 43,\n",
              " 'sagittarius': 44,\n",
              " 'science': 45,\n",
              " 'scorpio': 46,\n",
              " 'sports': 47,\n",
              " 'student': 48,\n",
              " 'taurus': 49,\n",
              " 'technology': 50,\n",
              " 'virgo': 51}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnNVx7nkqEbJ"
      },
      "source": [
        "####MultiClass labels into a matix of 1-hot using Multi-label Binarizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r0co0qr5ZYc"
      },
      "source": [
        "As the Y value here is composed of multiple classes for each input example, we cannot apply one hot as it to compare that with prediction, for this reason multilabelbinarizer helps\n",
        "MultiLabelBinarizer from sklearn is used to convert one hot of each unique classes in the input.\n",
        "With this as an actual input we can do prediction comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFRK9W_6pcfq"
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAGMJjLe58Bj"
      },
      "source": [
        "#We need the list of classes in the input to convert them to One-hot form using MLB\n",
        "#Creating list of unique classes\n",
        "labels_classes=[]\n",
        "\n",
        "for key in cv2.vocabulary_.keys():\n",
        "  labels_classes.append(key)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fwc2PYxsNFP",
        "outputId": "5f20a09a-076e-48e7-d288-2e547270d6bf"
      },
      "source": [
        "labels_classes"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['male',\n",
              " '15',\n",
              " 'student',\n",
              " 'leo',\n",
              " '33',\n",
              " 'investmentbanking',\n",
              " 'aquarius',\n",
              " 'female',\n",
              " '14',\n",
              " 'indunk',\n",
              " 'aries',\n",
              " '25',\n",
              " 'capricorn',\n",
              " '17',\n",
              " 'gemini',\n",
              " '23',\n",
              " 'non',\n",
              " 'profit',\n",
              " 'cancer',\n",
              " 'banking',\n",
              " '37',\n",
              " 'sagittarius',\n",
              " '26',\n",
              " '24',\n",
              " 'scorpio',\n",
              " '27',\n",
              " 'education',\n",
              " '45',\n",
              " 'engineering',\n",
              " 'libra',\n",
              " 'science',\n",
              " '34',\n",
              " '41',\n",
              " 'communications',\n",
              " 'media',\n",
              " 'businessservices',\n",
              " 'sports',\n",
              " 'recreation',\n",
              " 'virgo',\n",
              " 'taurus',\n",
              " 'arts',\n",
              " 'pisces',\n",
              " '44',\n",
              " '16',\n",
              " 'internet',\n",
              " 'museums',\n",
              " 'libraries',\n",
              " 'accounting',\n",
              " '39',\n",
              " '35',\n",
              " 'technology',\n",
              " '36']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEoMKh2487Vo"
      },
      "source": [
        "#Lets pass all the classes to MLB and create their function\n",
        "#Once 1-hot library is created, fit transform the train data to get their ony hot labels\n",
        "mlb = MultiLabelBinarizer(classes=labels_classes)\n",
        "labels_mlb=mlb.fit(df_t.labels.values)\n",
        "#train_labels = mlb.transform(y_train)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brtfiL4sS7GX",
        "outputId": "aeda02c6-c596-439b-b954-793e41897c6f"
      },
      "source": [
        "train_labels = mlb.transform(y_train)\n",
        "test_labels= mlb.transform(y_test)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:987: UserWarning: unknown class(es) ['communications-media', 'museums-libraries', 'non-profit', 'sports-recreation'] will be ignored\n",
            "  .format(sorted(unknown, key=str)))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqzctxDCvOiz",
        "outputId": "64ba26ae-e579-4f6c-fc01-6f4290434cb5"
      },
      "source": [
        "mlb.classes_"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['male', '15', 'student', 'leo', '33', 'investmentbanking',\n",
              "       'aquarius', 'female', '14', 'indunk', 'aries', '25', 'capricorn',\n",
              "       '17', 'gemini', '23', 'non', 'profit', 'cancer', 'banking', '37',\n",
              "       'sagittarius', '26', '24', 'scorpio', '27', 'education', '45',\n",
              "       'engineering', 'libra', 'science', '34', '41', 'communications',\n",
              "       'media', 'businessservices', 'sports', 'recreation', 'virgo',\n",
              "       'taurus', 'arts', 'pisces', '44', '16', 'internet', 'museums',\n",
              "       'libraries', 'accounting', '39', '35', 'technology', '36'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBe7nU0lRi3x",
        "outputId": "c55df917-463b-4657-e0d4-12c9094389a1"
      },
      "source": [
        "test_labels[433]"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7H744gi4x4ad",
        "outputId": "ce6d6e3d-353b-4b3c-90c8-67044efb00b5"
      },
      "source": [
        "y_test[433]"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['male', '35', 'technology', 'aries']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL426EOBCGYQ"
      },
      "source": [
        "###Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATiwDPkPG-FX"
      },
      "source": [
        "Linear classifiers are mostly binary classifiers\n",
        "\n",
        "As we are dealing with Multi class classification we need to use a classifier which will handle that.\n",
        "\n",
        "With One-vs-Rest classifier the multi class classification is broken into a series of Binary classifications, we can use a Linear model (logistic regression) for Binary Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1wVHx4-ni4S"
      },
      "source": [
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KELrTk_0iZi8",
        "outputId": "cf4cfe69-1494-47bd-b5b9-952f6bb6ad25"
      },
      "source": [
        "print(X_traincv.shape)\n",
        "print(x_testcv.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3000, 20000)\n",
            "(1000, 20000)\n",
            "(3000, 52)\n",
            "(1000, 52)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72a9DXU9T1PT"
      },
      "source": [
        "clf = LogisticRegression(solver = 'sag', max_iter=10000)\n",
        "clf = OneVsRestClassifier(clf)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXmlZVZcjEzs",
        "outputId": "25d88afb-e894-4448-a010-234eca8bc9fa"
      },
      "source": [
        "training=clf.fit(X_traincv,train_labels)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 16 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 17 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 33 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 34 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 36 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 37 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 45 is present in all training examples.\n",
            "  str(classes[c]))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/multiclass.py:75: UserWarning: Label not 46 is present in all training examples.\n",
            "  str(classes[c]))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n21n6_dxs4FB"
      },
      "source": [
        "###Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3p8uH2Njnoi"
      },
      "source": [
        "prediction=clf.predict(x_testcv)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jf6U0qxbkkTC",
        "outputId": "307a6857-bf12-47a8-f504-59d97a618a01"
      },
      "source": [
        "clf.score(x_testcv,test_labels)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.573"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A98WEU4kDKt"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c1K4Ec2kM96"
      },
      "source": [
        "cr=classification_report(test_labels,prediction,target_names= sorted(mlb.classes_),zero_division=1)"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYMm6MZFkVt4",
        "outputId": "42f00382-6ed3-4254-bff7-00d962761860"
      },
      "source": [
        "print(cr)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "               14       0.92      0.95      0.94       788\n",
            "               15       0.81      0.43      0.57        90\n",
            "               16       0.85      0.44      0.58       126\n",
            "               17       1.00      0.17      0.29        24\n",
            "               23       1.00      0.30      0.46        30\n",
            "               24       1.00      0.43      0.60        21\n",
            "               25       0.79      0.35      0.48        78\n",
            "               26       0.80      0.70      0.75       212\n",
            "               27       0.89      0.24      0.38        33\n",
            "               33       0.62      0.40      0.49       134\n",
            "               34       0.86      0.91      0.88       607\n",
            "               35       0.62      0.11      0.19        45\n",
            "               36       0.88      0.35      0.50        20\n",
            "               37       0.77      0.37      0.50        46\n",
            "               39       0.00      0.00      0.00        10\n",
            "               41       0.33      0.09      0.14        23\n",
            "               44       1.00      1.00      1.00         0\n",
            "               45       1.00      1.00      1.00         0\n",
            "       accounting       1.00      0.14      0.24        29\n",
            "         aquarius       1.00      0.00      0.00         7\n",
            "            aries       1.00      0.00      0.00         6\n",
            "             arts       0.33      0.07      0.12        27\n",
            "          banking       1.00      0.00      0.00         9\n",
            " businessservices       0.82      0.38      0.52        74\n",
            "           cancer       0.88      0.21      0.34        67\n",
            "        capricorn       0.25      0.07      0.11        14\n",
            "   communications       0.33      0.04      0.08        23\n",
            "        education       0.00      0.00      0.00         5\n",
            "      engineering       0.53      0.32      0.40        25\n",
            "           female       0.80      0.49      0.61        89\n",
            "           gemini       1.00      0.12      0.22         8\n",
            "           indunk       1.00      0.00      0.00         1\n",
            "         internet       1.00      0.00      0.00         3\n",
            "investmentbanking       1.00      1.00      1.00         0\n",
            "              leo       1.00      1.00      1.00         0\n",
            "            libra       1.00      0.25      0.40        16\n",
            "        libraries       1.00      1.00      1.00         0\n",
            "             male       1.00      1.00      1.00         0\n",
            "            media       1.00      0.00      0.00        11\n",
            "          museums       0.60      0.17      0.26        18\n",
            "              non       1.00      0.00      0.00         9\n",
            "           pisces       0.80      0.20      0.32        20\n",
            "           profit       1.00      0.00      0.00         1\n",
            "       recreation       1.00      0.00      0.00         6\n",
            "      sagittarius       1.00      0.20      0.33         5\n",
            "          science       1.00      1.00      1.00         0\n",
            "          scorpio       1.00      1.00      1.00         0\n",
            "           sports       1.00      1.00      1.00         0\n",
            "          student       0.60      0.13      0.21        23\n",
            "           taurus       0.88      0.92      0.90       574\n",
            "       technology       0.88      0.93      0.91       571\n",
            "            virgo       1.00      0.24      0.38        17\n",
            "\n",
            "        micro avg       0.86      0.73      0.79      3945\n",
            "        macro avg       0.82      0.39      0.44      3945\n",
            "     weighted avg       0.85      0.73      0.75      3945\n",
            "      samples avg       0.85      0.72      0.75      3945\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}